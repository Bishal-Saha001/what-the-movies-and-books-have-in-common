{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling in Books\n",
    "\n",
    "This notebook contains 2 sections, where we clean both book datasets: firstly, using the dataset with general information about books, useful to discover about languages, number of pages, publication years and average rating of a wide variety of books and then, applying some NLP pre-processing techniques to reader reviews, to do sentiment analysis and compare the patterns calculated with readers scores later. Additionally, we'll apply two different sentiment patterns criteria and we'll combine and compare the results to understand a little more about the people preferences. The resultant datasets are saved on processed Data folder to apply EDA and look for initial findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Books: general information\n",
    "\n",
    "In this section, we check the information on `book.csv` dataset and apply some preprocessing and wrangling steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant pachages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing `book1.csv` and `book2.csv` from the `interim` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book1 = pd.read_csv('../Data/interim/books/book1.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book1.dropna(subset=['description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book2 = pd.read_csv('../Data/interim/books/book2.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book2.dropna(subset=['description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book = pd.concat([df_book1, df_book2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the resultant dataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 825175 entries, 1 to 499996\n",
      "Data columns (total 29 columns):\n",
      "asin                    141201 non-null object\n",
      "authors                 825175 non-null object\n",
      "average_rating          825175 non-null float64\n",
      "book_id                 825175 non-null int64\n",
      "country_code            825175 non-null object\n",
      "description             825175 non-null object\n",
      "edition_information     84392 non-null object\n",
      "format                  661449 non-null object\n",
      "image_url               825175 non-null object\n",
      "is_ebook                825175 non-null object\n",
      "isbn                    502210 non-null object\n",
      "isbn13                  583432 non-null object\n",
      "kindle_asin             361286 non-null object\n",
      "language_code           492893 non-null object\n",
      "link                    825175 non-null object\n",
      "num_pages               612922 non-null float64\n",
      "popular_shelves         825175 non-null object\n",
      "publication_day         529733 non-null float64\n",
      "publication_month       582375 non-null float64\n",
      "publication_year        675718 non-null float64\n",
      "publisher               653616 non-null object\n",
      "ratings_count           825175 non-null float64\n",
      "series                  825175 non-null object\n",
      "similar_books           825175 non-null object\n",
      "text_reviews_count      825175 non-null float64\n",
      "title                   825174 non-null object\n",
      "title_without_series    825174 non-null object\n",
      "url                     825175 non-null object\n",
      "work_id                 825175 non-null float64\n",
      "dtypes: float64(8), int64(1), object(20)\n",
      "memory usage: 188.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_book.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that some columns are not complete (`publiser`, `isbn`), but we focus just in relevant columns, as:\n",
    "- authors\n",
    "- average_rating\n",
    "- book_id\n",
    "- description\n",
    "- is_ebook\n",
    "- language_code\n",
    "- num_pages\n",
    "- publication_year\n",
    "- ratings_count\n",
    "- similar_books\n",
    "- title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_ = df_book.copy()\n",
    "df_book_ = df_book_.loc[:, ['authors', 'average_rating', 'book_id', \n",
    "                            'description', 'is_ebook', 'language_code',\n",
    "                            'num_pages', 'publication_year', 'ratings_count',\n",
    "                            'similar_books', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions that we must answer are, for instances: \n",
    "\n",
    "1. Are we including dictionaries in this analysis? We must consider that the number of pages of dictionaries are larger than common books.\n",
    "2. Are data about publication year consistent and correct? \n",
    "3. How many people evaluated the books on the ranking? A book with one evaluation can't be consider in the same category of books with hundred or thousand of evaluations.\n",
    "4. Must be delete the books with incomplete data? Probably not, because using the language code as criteria we should delete almost 40% of books, but in opposite, we see that descriptions, titles and authors are complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Filtering dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = []\n",
    "for title in df_book.title:\n",
    "    if re.search(r'dictionary', str(title).lower()) is None:\n",
    "        dictionary.append(0)\n",
    "    else:\n",
    "        dictionary.append(1)\n",
    "        \n",
    "df_book['is_dictionary'] = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>book_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>description</th>\n",
       "      <th>edition_information</th>\n",
       "      <th>format</th>\n",
       "      <th>image_url</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>...</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>series</th>\n",
       "      <th>similar_books</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>title</th>\n",
       "      <th>title_without_series</th>\n",
       "      <th>url</th>\n",
       "      <th>work_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_dictionary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141187</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "      <td>84337</td>\n",
       "      <td>661011</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "      <td>...</td>\n",
       "      <td>675273</td>\n",
       "      <td>653174</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "      <td>824678</td>\n",
       "      <td>824678</td>\n",
       "      <td>824679</td>\n",
       "      <td>824679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>55</td>\n",
       "      <td>438</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>...</td>\n",
       "      <td>445</td>\n",
       "      <td>442</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 asin  authors  average_rating  book_id  country_code  \\\n",
       "is_dictionary                                                           \n",
       "0              141187   824679          824679   824679        824679   \n",
       "1                  14      496             496      496           496   \n",
       "\n",
       "               description  edition_information  format  image_url  is_ebook  \\\n",
       "is_dictionary                                                                  \n",
       "0                   824679                84337  661011     824679    824679   \n",
       "1                      496                   55     438        496       496   \n",
       "\n",
       "                ...     publication_year  publisher  ratings_count  series  \\\n",
       "is_dictionary   ...                                                          \n",
       "0               ...               675273     653174         824679  824679   \n",
       "1               ...                  445        442            496     496   \n",
       "\n",
       "               similar_books  text_reviews_count   title  \\\n",
       "is_dictionary                                              \n",
       "0                     824679              824679  824678   \n",
       "1                        496                 496     496   \n",
       "\n",
       "               title_without_series     url  work_id  \n",
       "is_dictionary                                         \n",
       "0                            824678  824679   824679  \n",
       "1                               496     496      496  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_book.groupby('is_dictionary').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are almost 500 documents belongs to the category of Dictionary. We filter them using `is_dictionary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_noDict = df_book[df_book['is_dictionary'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Outliers in rating counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are curious to work with the `average_rating` of books, we need to consider how many `rating_count` has every one and delete **outliers**. For instance, the `average_rating` of books with just one `rating_count` can't be compared with other with one hundred of counts. To deal with these differences, we calculate the **z score** of every rating count and filter books with z > 3 (standard threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(df_book_noDict.ratings_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_noDict = df_book_noDict[(z < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Average Rating vs Absolute Ratings\n",
    "\n",
    "We add an absolute rating column that round ratings to get scores between 0 and 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_noDict['abs_rating'] = round(df_book_noDict.average_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Outliers in number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_noDict.dropna(subset=['num_pages'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pages = np.abs(stats.zscore(df_book_noDict.num_pages))\n",
    "df_book_noDict = df_book_noDict[(z_pages < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Publication year: sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we build a `df_book_noDict_year` that delete missing years and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_noDict.dropna(subset=['publication_year'], inplace=True)\n",
    "z_year = np.abs(stats.zscore(df_book_noDict.publication_year))\n",
    "df_book_noDict_year = df_book_noDict[(z_year < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the dataFrames `df_book_noDict` and `df_book_noDict_year`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_book_noDict.to_csv('../Data/processed/books/books_noDict.csv')\n",
    "#df_book_noDict_year.to_csv('../Data/processed/books/books_noDict_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Book Reviews: preprocessing\n",
    "\n",
    "It's time to check the books_reviews.csv dataset and apply some nlp preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('../Data/interim/books/books_reviews.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>has_spoiler</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_sentences</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18245960</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n",
       "      <td>[[0, 'This is a special book.'], [0, 'It start...</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16981</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n",
       "      <td>[[0, 'Recommended by Don Katz.'], [0, 'Avail f...</td>\n",
       "      <td>2017-03-22</td>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id  has_spoiler  rating                         review_id  \\\n",
       "0  18245960         True       5  dfdbb7b0eb5a7e4c26d59a937e2e5feb   \n",
       "1     16981        False       3  a5d2c3628987712d0e05c4f90798eb67   \n",
       "\n",
       "                                    review_sentences   timestamp  \\\n",
       "0  [[0, 'This is a special book.'], [0, 'It start...  2017-08-30   \n",
       "1  [[0, 'Recommended by Don Katz.'], [0, 'Avail f...  2017-03-22   \n",
       "\n",
       "                            user_id  \n",
       "0  8842281e1d1347389f2ab93d60773d4d  \n",
       "1  8842281e1d1347389f2ab93d60773d4d  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1378033 entries, 0 to 1378032\n",
      "Data columns (total 7 columns):\n",
      "book_id             1378033 non-null int64\n",
      "has_spoiler         1378033 non-null bool\n",
      "rating              1378033 non-null int64\n",
      "review_id           1378033 non-null object\n",
      "review_sentences    1378033 non-null object\n",
      "timestamp           1378033 non-null object\n",
      "user_id             1378033 non-null object\n",
      "dtypes: bool(1), int64(2), object(4)\n",
      "memory usage: 64.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we merge 3 columns of `df_books_`: `book_id`, `title`, `description` with this dataFrame to posterior analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_esential = df_book_.loc[:, ['book_id', 'title', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books_reviews = df_reviews.merge(df_book_esential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>has_spoiler</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_sentences</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16981</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n",
       "      <td>[[0, 'Recommended by Don Katz.'], [0, 'Avail f...</td>\n",
       "      <td>2017-03-22</td>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>Invisible Man</td>\n",
       "      <td>First published in 1952 and immediately hailed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16981</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>706a8032efbde550167bf0d96c2ab501</td>\n",
       "      <td>[[0, 'This book was actually good, so long tho...</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>2159f55d397e8fbe68d5e03668e7d9d2</td>\n",
       "      <td>Invisible Man</td>\n",
       "      <td>First published in 1952 and immediately hailed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  has_spoiler  rating                         review_id  \\\n",
       "0    16981        False       3  a5d2c3628987712d0e05c4f90798eb67   \n",
       "1    16981        False       4  706a8032efbde550167bf0d96c2ab501   \n",
       "\n",
       "                                    review_sentences   timestamp  \\\n",
       "0  [[0, 'Recommended by Don Katz.'], [0, 'Avail f...  2017-03-22   \n",
       "1  [[0, 'This book was actually good, so long tho...  2015-02-25   \n",
       "\n",
       "                            user_id          title  \\\n",
       "0  8842281e1d1347389f2ab93d60773d4d  Invisible Man   \n",
       "1  2159f55d397e8fbe68d5e03668e7d9d2  Invisible Man   \n",
       "\n",
       "                                         description  \n",
       "0  First published in 1952 and immediately hailed...  \n",
       "1  First published in 1952 and immediately hailed...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books_reviews.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we apply NLP pre-processing techniques such as subtraction of special characters, tokenization and lemmatization of the words. We define a pre-processing function as a pipeline of the methods mentioned and a sentiment_parameters_Pattern that calculate the polarity and subjectivity pattern of every review. In this case, we measure polarity using TextBlob and Afinn. Finally, we include the review normalized and the sentiment patterns using TextBlob and Afinn on the books_reviews dataFrame and save as csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from textblob.sentiments import PatternAnalyzer\n",
    "from textblob import TextBlob\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing the AFINN package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building `expandContractions` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "all credits go to alko and arturomp @ stack overflow.\n",
    "\"\"\"\n",
    "\n",
    "with open('../Data_preprocessing/wordLists/contractionList.txt', 'r') as f:\n",
    "    cList = json.loads(f.read())\n",
    "    c_re = re.compile('(%s)' % '|'.join(cList.keys()))\n",
    "\n",
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return cList[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline preprocessing\n",
    "\n",
    "1. Normalize and expand contractions\n",
    "2. Delete spetial characters\n",
    "3. Tokenize words\n",
    "4. Lemmatization\n",
    "5. Join sentences again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building `pre_processing` and `sentiment_parameters_Pattern` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def pre_processing(text):\n",
    "    text = re.sub(r'’',\"'\", text)\n",
    "    text = expandContractions(text.lower())\n",
    "    text = text.lower()\n",
    "    # Filtering special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]','', text)\n",
    "    # Tokenization and filtering stop-words\n",
    "    tokens = wpt.tokenize(text)\n",
    "    # Lemmatization\n",
    "    words_lem = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    text_norm = ' '.join(words_lem)\n",
    "    \n",
    "    return text_norm\n",
    "\n",
    "def sentiment_parameters_Pattern(sentence):\n",
    "    blob = TextBlob(sentence, analyzer=PatternAnalyzer())\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing `reviews_sentences`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_normalized = [pre_processing(text) for text in df_books_reviews['review_sentences']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the normalized reviews as a new column of `df_books_reviews`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books_reviews['text_normalized'] = text_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the polarity and subjectivity patterns of every review normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pattern = [sentiment_parameters_Pattern(text) for text in text_normalized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving new columns with the patterns extracted in `df_books_reviews`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_textBlob = [sentiment_pattern[i][0] for i in range(len(sentiment_pattern))]\n",
    "subjectivity_textBlob = [sentiment_pattern[j][1] for j in range(len(sentiment_pattern))]\n",
    "df_books_reviews['polarity_textBlob'] = polarity_textBlob\n",
    "df_books_reviews['subjectivity_textBlob'] = subjectivity_textBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use AFINN lexicon to measure the polarity of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = Afinn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure the polarity according AFINN lexicon and then, we classify the sentences in positive, negative or neutral, depending on the polarity score. Then, we include both as new columns of `df_books_reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = [af.score(text) for text in text_normalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_category = ['positive' if score > 0 \n",
    "                          else 'negative' if score < 0 \n",
    "                              else 'neutral' \n",
    "                                  for score in sentiment_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books_reviews['sentiment_scores'] = sentiment_scores\n",
    "df_books_reviews['sentiment_category'] = sentiment_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we save the file in the `processed` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_books_reviews.to_csv('../Data/processed/books/sentiment_patterns_books_reviews.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
